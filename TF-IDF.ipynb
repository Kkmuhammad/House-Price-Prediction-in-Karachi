{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## processing text data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#project_folder=\"C:/Users/muhammadkashifkhan/Documents/ASDS_2nd/Thesis/output_kashif/\"\n",
    "#output_folder=project_folder+\"output\"\n",
    "\n",
    "df=pd.read_csv(\"cleaned_khi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"Description\":\"description\"} , inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option(\"display.max_rows\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords') \n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages and modules\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[\"description\"][533]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check the 8 digit at the end of each description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"misterious_number\"]=df[\"description\"].str.extract(r\"(\\d\\d\\d\\d\\d\\d\\d\\d)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.misterious_number.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## based on the manual inspection, the misterious number cannot indicate if the builidings are the same, or the realtor is the same, or even the realtor company is the same.\n",
    "\n",
    "## Therefore, remove the 8 digits at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(\"\\(\\d\\d\\d\\d\\d\\d\\d\\d\\)\", \"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix some abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace Apostrophe ' with no string\n",
    "df[\"description\"]=df[\"description\"].str.replace('\\'', \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace('.5 ', \" and a half \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace(' c-vac ', \" cvac \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace(' d/w', \" dishwasher \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace(' w&d', \" washer and dryer \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace(' d/w', \" dryer \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace('w/o', \" walk out \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace(r' [wW][/\\s]r[.\\s]', \" washroom \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace(r' [wW]/', \" with \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace(r' [wW]\\&[dD][.\\s]', \" washer and dryer \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace(r'\\ss/s\\s', \" ss \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace('bdrm', \"bedroom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace('bsmt', \"basement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace('+', \" plus \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace('&', \" and \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('\\$', \" CAD \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('don\\'t', \" do not \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('doesn\\'t', \" does not \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('can\\'t', \" cannot \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace('\\'ll ', \" will \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "df['description'] = df['description'].apply(lambda x: re.sub(r'(\\d+),(\\d+)', r'\\1\\2', x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization to remove the special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokeniser = RegexpTokenizer(r'\\w+')\n",
    "df[\"description\"]=df[\"description\"].apply(lambda x: tokeniser.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"description\"][-30:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## detokenlization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].apply(lambda x: \" \".join(word for word in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.description.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert ordinal number to words, such as 1st--> first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from num2words import num2words\n",
    "def replace_ordinal_numbers(text):\n",
    "    re_results = re.findall('(\\d+(st|nd|rd|th))', text)\n",
    "    for enitre_result, suffix in re_results:\n",
    "        num = int(enitre_result[:-2])\n",
    "        text = text.replace(enitre_result, num2words(num, ordinal=True))\n",
    "    return text\n",
    "df[\"description\"]=df[\"description\"].apply(lambda x: replace_ordinal_numbers(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert \" w \" or \" W \" to \"with\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace(r' [wW] ', \" with \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove single characters except \"a\" or number first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace(r'\\s[bcdefghijklmnopqrstuvwxyzBCDEFGHIJKLMNOPQRSTUVWXYZ]\\s', \" \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(r'\\s[bcdefghijklmnopqrstuvwxyzBCDEFGHIJKLMNOPQRSTUVWXYZ]\\s', \" \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(r'\\s[bcdefghijklmnopqrstuvwxyzBCDEFGHIJKLMNOPQRSTUVWXYZ]\\s', \" \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(r'\\s[bcdefghijklmnopqrstuvwxyzBCDEFGHIJKLMNOPQRSTUVWXYZ]$', \" \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(r'^[bcdefghijklmnopqrstuvwxyzBCDEFGHIJKLMNOPQRSTUVWXYZ]\\s', \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deal with abbreviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace(' 1st ', \" first \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' 1st$', \" first \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^1st ', \" first \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' 2nd ', \" second \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' 2nd$', \" second \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^2nd ', \" second \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' 3rd ', \" third \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' 3rd$', \" third \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^3rd ', \" third \")\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' 4th ', \" fourth \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' 4th$', \" fourth \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^4th ', \" fourth \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' 5th ', \" fifth \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' 5th$', \" fifth \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^5th ', \" fifth \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' 6th ', \" sixth \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' 6th$', \" sixth \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^6th ', \" sixth \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' 7th ', \" seventh \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' 7th$', \" seventh \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^7th ', \" seventh \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' 8th ', \" eighth \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' 8th$', \" eighth \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^8th ', \" eighth \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' 9th ', \" ninth \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' 9th$', \" ninth \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^9th ', \" ninth \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seperate number and alphabetical characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace('(\\d+(\\.\\d+)?)', r' \\1 ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sep usually means \"seperate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace(' sep ', \" separate \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hwy means \"highway\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace(' hwy ', \" highway \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' hwy$', \" highway \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^hwy ', \" highway \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bdr, bedrm means bedroom\n",
    "## washrm means washroom\n",
    "##  rm means room "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace(' bdr ', \" bedroom \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' bdr$', \" bedroom \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^bdr ', \" bedroom \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace('bedrm', \"bedroom\")\n",
    "df[\"description\"]=df[\"description\"].str.replace('washrm', \"washroom\")\n",
    "df[\"description\"]=df[\"description\"].str.replace('bathrm', \"bathroom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace(' rm ', \" room \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert square feet to sqft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace(' sq ft ', \" sqft \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('sqft', \" sqft \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' sqf ', \" sqft \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' sf ', \" sqft \")\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace('square ft', \" sqft \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('square feet', \" sqft \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('square foot', \" sqft \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('sq feet', \" sqft \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('sq foot', \" sqft \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' sqft ', \" square feet \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert abbreviation and mis-spelled word to the correct form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace('hardwd', \"hardwood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace('addtl', \"additional\")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' lvl ', \" level \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' lvl$', \" level \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^lvl ', \" level \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' lwr ', \" lower \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^lwr ', \" lower \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' lwr$', \" lower \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' fl ', \" floor \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' flr ', \" floor \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' flrs ', \" floors \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' flring ', \" flooring \")\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' reno ', \" renovated \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' entr ', \" entrance \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' ent ', \" entrance \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' balciony ', \" balcony \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' semidetached ', \" semi detached \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace(' incl ', \" include \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' excl ', \" exclude \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' exl ', \" exclude \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' pcs ', \" pieces \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' pc ', \" piece \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace('dinning', \"dining\")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' stn ', \" station \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' dw ', \" dishwasher \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' ctr ', \" center \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' centre ', \" center \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace('rec room', \"recreation room\")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' cvac ', \" central vacuum \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' central vac ', \" central vacuum \")\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' st ', \" street \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace('bk yard', \" back yard \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' backyard ', \" back yard \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' ac ', \" air conditioner \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' da ', \" the \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' kit ', \" kitchen \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' kitch ', \" kitchen \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' u ', \" you \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' ur ', \" your \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' urself ', \" yourself \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' what 2 do ', \" what to do \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' dont ', \" do not \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' cul de sac ', \" culdesac \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' through out ', \" throughout \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' thru out ', \" throughout \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' hr ', \" hour \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' bld ', \" boulevard \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' remks ', \" remarks \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' fire place ', \" fireplace \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' ss ', \" stainless steel \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' hwt ', \" hot water tank \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' hwt$', \" hot water tank \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' hwts ', \" hot water tank \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' hwts$', \" hot water tank \")\n",
    "\n",
    " \n",
    "df[\"description\"]=df[\"description\"].str.replace(' incl ', \" include \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' incl$', \" include \")\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' incls ', \" include \")\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' inc ', \" include \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' excl ', \" exclude \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' exl ', \" exclude \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' excls ', \" exclude \")\n",
    "\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' pcs ', \" pieces \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' pc ', \" piece \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace('dinning', \"dining\")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' stn ', \" station \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' dw ', \" dishwasher \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' ctr ', \" center \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' centre ', \" center \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace('rec room', \"recreation room\")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' cvac ', \" central vac \")\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' st ', \" street \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace('bk yard', \" back yard \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' back yard ', \" backyard \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' ac ', \" air conditioner \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' da ', \" the \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' kit ', \" kitchen \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' kitch ', \" kitchen \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' kitn ', \" kitchen \")\n",
    "\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' u ', \" you \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' ur ', \" your \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' urself ', \" yourself \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' what 2 do ', \" what to do \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' dont ', \" do not \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' don miss', \" do not miss\")\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' cul de sac ', \" culdesac \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' through out ', \" throughout \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' thru out ', \" throughout \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' thruout ', \" throughout \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' thr out ', \" throughout \")\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' thru ', \" through \")\n",
    "\n",
    "\n",
    " \n",
    "df[\"description\"]=df[\"description\"].str.replace(' hr ', \" hour \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' hrs ', \" hours \")\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' bld ', \" boulevard \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' remks ', \" remarks \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' fire place ', \" fireplace \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' ss ', \" stainless steel \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' tvs ', \" television \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' tv ', \" television \")\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' br ', \" bedroom \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' br$', \" bedroom \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' brm ', \" bedroom \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' brs ', \" bedrooms \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' pre emptive ', \" preemptive \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' pre ', \" previously \")\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' eng hardwood ', \" engineered hardwood \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' bksplsh ', \" backsplash \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' bathflrs ', \" bath floors \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' grnd ', \" ground \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' fl washer ', \" front load \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' gdo ', \" garage door opener \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' gdo$', \" garage door opener \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' cac ', \" central air conditioner \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' quite street ', \" quiet street \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' dist ', \" distance \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' abv ', \" above \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' bkfst ', \" breakfast \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' lrg ', \" large \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' hdwd ', \" hardwood \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' hrdwd ', \" hardwood \")\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' cntp ', \" countertop \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' rntl ', \" rental \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' rntl$', \" rental \")\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' bbq ', \" barbeque \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' bbq$', \" barbeque \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' pls ', \" please \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' pls$', \" please \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' apt$', \" apartment \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' apt ', \" apartment \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^apt ', \" apartment \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' lr ', \" living room \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' dr ', \" dining room \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' fp ', \" fireplace \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' dble ', \" double \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' dbl ', \" double \")\n",
    "\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' gar ', \" garage \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' approx ', \" approximately \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' appr ', \" approximately \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^appr ', \" approximately \")\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' fab ', \" fabulous \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^fab ', \" fabulous \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' fab$', \" fabulous \")\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' bed ', \" bedroom \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' bath ', \" bathroom \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' potlights ', \" pot lights \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' ave ', \" avenue \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' atn ', \" attention \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' attn ', \" attention \")\n",
    "\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' cre ', \" crescent \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' cres ', \" crescent \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' prem ', \" premium \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' cntr ', \" center \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' dvp ', \" don valley parkway \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' lgl ', \" legal \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' desc ', \" description \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' twp ', \" township \")\n",
    "\n",
    "#df[\"description\"]=df[\"description\"].str.replace(' ttc ', \" toronto transit commission \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' maint ', \" maintenance \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' incd ', \" included \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' incd$', \" included \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' incld ', \" include \")\n",
    "\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' avbl ', \" available \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' avbl$', \" available \")\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' ft ', \" feet \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' ft$', \" feet \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^ft ', \" feet \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' equiment ', \" equipment \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^equiment ', \" equipment \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' equiment$', \" equipment \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' min ', \" minute \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' mins ', \" minute \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' uft ', \" university of toronto \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' uoft ', \" university of toronto \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' hm ', \" home \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' mnth ', \" month \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' apprx ', \" approximately \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' sq ', \" square \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^sq ', \" square \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' sq$', \" square \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' appx ', \" approximate \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' you re ', \" you are \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' ciity  ', \" city \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' xcellent ', \" excellent \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^xcellent ', \" excellent \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' xcellent$', \" excellent \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' mt pleasant ', \" mount pleasant \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^mt pleasant ', \" mount pleasant \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' mt pleasant$', \" mount pleasant \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' liv ', \" living \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' din ', \" dining \")\n",
    " \n",
    "df[\"description\"]=df[\"description\"].str.replace(' ameneties ', \" amenities \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' frt ', \" front \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' centres ', \" center \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' rec ', \" recreation \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' crt ', \" crescent \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' lg ', \" large \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' walkin ', \" walking \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' fin ', \" finished \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' wdws ', \" windows \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' wd ', \" wood \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' egdo ', \" electric garage door \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' hwys ', \" highway \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' hwys$', \" highway \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' fam ', \" family \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' comm ', \" community \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' prefect ', \" perfect \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' washer dyer ', \" washer dryer \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' washer and dyer ', \" washer and dryer \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' det house ', \" detached house \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' roughin ', \" rough in \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' walkout ', \" walk out \")\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' mldg ', \" molding \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' mldgs ', \" molding \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' prof ', \" professional \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' carbon mon ', \" carbon monoxide \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' chdlr ', \" chandelier \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' condationer ', \" conditioner \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' ext ', \" extras \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' en suite ', \" ensuite \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' air condition ', \" air conditioner \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' air conditioning ', \" air conditioner \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' refrigerator ', \" fridge \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' tlc ', \" tender loving care \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' nw facing ', \" northwest facing \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' nw ', \" northwest \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' sw ', \" southwest \")\n",
    "\n",
    " \n",
    "df[\"description\"]=df[\"description\"].str.replace(' ffice ', \" office \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' ens bathroom ', \" ensuite bathroom \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' prkg ', \" parking \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' prkg$', \" parking \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' pking ', \" parking \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' pking$', \" parking \")\n",
    "\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' hdwr ', \" hardware \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' est ', \" estimated \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' estm ', \" estimated \")\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' mn ', \" main \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' linc ', \" lincoln alexander parkway \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' won be ', \" will not \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' blt in ', \" built in \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' porcelin ', \" porcelain \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' oc transpo ', \" octranspo \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' oc transpo$', \" octranspo \")\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' yr ', \" year \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^yr ', \" year \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' yr$', \" year \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' yrs ', \" years \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^yrs ', \" years \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' yrs$', \" years \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' detach home ', \" detached home \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' mstr ', \" master \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' mbr ', \" master bedroom \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' mbr$', \" master bedroom \")\n",
    "\n",
    " \n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' utm ', \" university of toronto mississauga \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' theater ', \" theatre \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' nannysuite ', \" nanny suite \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' neighborhood ', \" neighbourhood \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' specious ', \" spacious \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' roof top ', \" rooftop \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' insur ', \" insurance \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' buildin ', \" building \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^buildin ', \" building \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' buildin$', \" building \")\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' bldg ', \" building \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^bldg ', \" building \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' bldg$', \" building \")\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' bsmnt ', \" basement \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' coin op ', \" coin operated \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' turn key ', \" turnkey \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' qew ', \" queen elizabeth way \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^qew ', \" queen elizabeth way \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' qew$', \" queen elizabeth way \")\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' larage ', \" large \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' lge ', \" large \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^lge ', \" large \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' lge$', \" large \")\n",
    "\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' rangehood', \" range hood \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace('breath taking', \"breathtaking\")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace('gardnier', \"gardiner\")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace('over the range microwave', \"otr microwave\")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace('over range microwave', \"otr microwave\")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' equiped ', \" equipped \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace('water front', \"waterfront\")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' pen concept ', \" open concept \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' re modeled ', \" remodeled \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' hottub ', \" hot hub \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' carwash ', \" car wash \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' carwash$', \" car wash \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' back splash ', \" backsplash \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^back splash ', \" backsplash \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' back splash$', \" backsplash \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' pce ', \" piece \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' pice ', \" piece \")\n",
    "\n",
    " \n",
    "df[\"description\"]=df[\"description\"].str.replace(' appl ', \" appliance \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' app ', \" appliance \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' appls ', \" appliances \")\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' wsher ', \" washer \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' attachd ', \" attached \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' attachd$', \" attached \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^attachd ', \" attached \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' soughtafter ', \" sought after \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' bthrms ', \" bathrooms \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' bthrms$', \" bathrooms \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^bthrms ', \" bathrooms \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' bthrm ', \" bathroom \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' bthrm$', \" bathroom \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^bthrm ', \" bathroom \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' you ve ', \" you have \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^you ve ', \" you have \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' strge ', \" storage \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' strge$', \" storage \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^strge ', \" storage \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' lyr ', \" layer \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' lyr$', \" layer \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^lyr ', \" layer \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' dish washer', \" dishwasher \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' wr ', \" washroom \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' wr$', \" washroom \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' quite crescent ', \" quiet crescent \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^quite crescent ', \" quiet crescent \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' quite crescent$', \" quiet crescent \")\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' side walk ', \" sidewalk \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^side walk ', \" sidewalk \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' side walk$', \" sidewalk \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' mordern ', \" modern \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' mordern$', \" modern \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^mordern ', \" modern \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' neighbors ', \" neighbours \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^neighbors ', \" neighbours \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' neighbors$', \" neighbours \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' neighbor ', \" neighbour \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^neighbor ', \" neighbour \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' neighbor$', \" neighbour \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' floorplan ', \" floor plan \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' re development ', \" redevelopment \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' ev ', \" electric vehicle \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' super market ', \" supermarket \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' super market$', \" supermarket \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^super market ', \" supermarket \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' etobicoke ci ', \" etobicoke collegiate institute \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' insp ', \" inspection \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^insp ', \" inspection \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' insp$', \" inspection \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' exec ', \" executive \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^exec ', \" executive \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' exec$', \" executive \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' rms ', \" rooms \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^rms ', \" rooms \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' rms$', \" rooms \")\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' hw ', \" hardwood floor \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^hw ', \" hardwood floor \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' hw$', \" hardwood floor \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' hwf ', \" hardwood floor \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^hwf ', \" hardwood floor \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' hwf$', \" hardwood floor \")\n",
    "\n",
    " \n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' gb ', \" gas burner \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^gb ', \" gas burner \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' gb$', \" gas burner \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' lph ', \" lower penthouse \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^lph ', \" lower penthouse \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' lph$', \" lower penthouse \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' locaction ', \" locaction \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^locaction ', \" locaction \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' locaction$', \" locaction \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' mic ', \" microwave \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' mic$', \" microwave \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' micro ', \" microwave \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' micro$', \" microwave \")\n",
    "\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' lckr ', \" locker \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' lckr$', \" locker \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^lckr ', \" locker \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' counter tops ', \" countertops \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' counter tops$', \" countertops \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^counter tops ', \" countertops \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' counter top ', \" countertop \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' counter top$', \" countertop \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^counter top ', \" countertop \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' nac ', \" national art center \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' nac$', \" national art center \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^nac ', \" national art center \")\n",
    "\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' south west ', \" southwest \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' over sized ', \" oversized \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' exisiting ', \" existing \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' orig ', \" original \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' spc ', \" space \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' spc$', \" space \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' fr ', \" family room \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' fr$', \" family room \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' stv ', \" stove \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' stv$', \" stove \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' wndw ', \" window \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^wndw ', \" window \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' wndw$', \" window \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' crt ', \" court \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^crt ', \" court \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' crt$', \" court \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' crts ', \" courts \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^crts ', \" courts \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' crts$', \" courts \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' hobbyistes ', \" hobbyistes \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^hobbyistes ', \" hobbyistes \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' hobbyistes$', \" hobbyistes \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' smarthome ', \" smart home \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^smarthome ', \" smart home \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' smarthome$', \" smart home \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' cook top ', \" cooktop \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' cook top$', \" cooktop \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' bath ', \" bathroom \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^bath ', \" bathroom \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' bath$', \" bathroom \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' baths ', \" bathrooms \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^baths ', \" bathrooms \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' baths$', \" bathrooms \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' wfh ', \" work from home \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^wfh ', \" work from home \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' wfh$', \" work from home \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' bckyrd ', \" backyard \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^bckyrd ', \" backyard \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' bckyrd$', \" backyard \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' busses ', \" buses \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^busses ', \" buses \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' busses$', \" buses \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' two story ', \" two storey \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^two story ', \" two storey \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' two story$', \" two storey \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' nyc ', \" new york city \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^nyc ', \" new york city \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' nyc$', \" new york city \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' xtra ', \" extra \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^xtra ', \" extra \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' xtra$', \" extra \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' opprtnty ', \" opportunity \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^opprtnty ', \" opportunity \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' opprtnty$', \" opportunity \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' nghbrhd ', \" neighbourhood \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^nghbrhd ', \" neighbourhood \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' nghbrhd$', \" neighbourhood \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' cncpt ', \" concept \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^cncpt ', \" concept \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' cncpt$', \" concept \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' expsr ', \" exposure \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^expsr ', \" exposure \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' expsr$', \" exposure \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' wdw ', \" window \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^wdw ', \" window \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' wdw$', \" window \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' entrce ', \" entrance \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^entrce ', \" entrance \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' entrce$', \" entrance \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' xl ', \" extra large \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^xl ', \" extra large \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' xl$', \" extra large \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' equip ', \" equipment \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^equip ', \" equipment \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' equip$', \" equipment \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' blk ', \" black \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^blk ', \" black \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' blk$', \" black \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' sytem ', \" system \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^sytem ', \" system \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' sytem$', \" system \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' hook up ', \" hookup \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^hook up ', \" hookup \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' hook up$', \" hookup \")\n",
    "\n",
    "df[\"description\"]=df[\"description\"].str.replace(' elf ', \" electric lights fixtures \")\n",
    "df[\"description\"]=df[\"description\"].str.replace('^elf ', \" electric lights fixtures \")\n",
    "df[\"description\"]=df[\"description\"].str.replace(' elf$', \" electric lights fixtures \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the phone number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace(r'\\d\\d\\d\\s?\\d\\d\\d\\s?\\d\\d\\d\\d', \" \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## convert \" k \" to \" thousand \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace(' k ', \" thousand \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove more than 1 spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace(\"\\s\\s+\", \" \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove single character except \"a\" or number again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].str.replace(r'\\s[bcdefghijklmnopqrstuvwxyzBCDEFGHIJKLMNOPQRSTUVWXYZ]\\s', \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## df[\"description\"]=df[\"description\"].str.replace(r'\\d+', \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "rdm_indx=randrange(30, 700)\n",
    "print(rdm_indx)\n",
    "df[\"description\"][rdm_indx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the number of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Total words\n",
    "df[\"total_words\"] = df[\"description\"].str.split().str.len()\n",
    "count_total=df[\"total_words\"].sum()\n",
    "print(\"number of all words (non unique): \"+str(count_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique words\n",
    "uniqueWords = list(set(\" \".join(df[\"description\"]).split(\" \")))\n",
    "count = len(uniqueWords)\n",
    "print(\"number of unique words: \"+str(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try the TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_test=df.head().copy()\n",
    "# Unique words\n",
    "uniqueWords = list(set(\" \".join(df_test[\"description\"]).split(\" \")))\n",
    "count = len(uniqueWords)\n",
    "print(\"number of unique words: \"+str(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from textblob import TextBlob \n",
    "from textblob import Word\n",
    "\n",
    "df_test[\"description\"] = df_test[\"description\"].apply(lambda x: \"\".join(TextBlob(x).correct()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df_test[\"description\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the word and abbrivation changed too much\n",
    "## spelling correction using TextBlob will not be used "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenization again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokeniser = RegexpTokenizer(r'\\w+')\n",
    "df[\"description\"]=df[\"description\"].apply(lambda x: tokeniser.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.description.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert words to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from word2number import w2n\n",
    "def numtoword(text_tokens):\n",
    "    new_list=[]\n",
    "    for word in text_tokens:\n",
    "        try: \n",
    "            word=w2n.word_to_num(word)\n",
    "            new_list.append(word)\n",
    "        except: \n",
    "            new_list.append(word)\n",
    "    return new_list\n",
    "\n",
    "df['description'] = df['description'].apply(lambda x: numtoword(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.description.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatiser = WordNetLemmatizer()\n",
    "df[\"description\"]=df[\"description\"].apply(lambda x: [lemmatiser.lemmatize(str(word)) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.description.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save the lemmatized data as df_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## detokenization\n",
    "df[\"description\"]=df[\"description\"].apply(lambda x: \" \".join(word for word in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lem=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lem.to_csv(output_kashif+\"/\"+\"all_after_preprocessingLem.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##tokenization\n",
    "tokeniser = RegexpTokenizer(r'\\w+')\n",
    "df[\"description\"]=df[\"description\"].apply(lambda x: tokeniser.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_nltk=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_estate_stopwords = [\n",
    "    \"area\",\n",
    "    \"province\",\n",
    "    \"location\",\n",
    "    \"plot\",\n",
    "    ## common measurement\n",
    "    \"hectare\",\n",
    "    \"acre\",\n",
    "    \"m\",\n",
    "    \"m2\",\n",
    "    \"sq\",\n",
    "    \"sale\",\n",
    "    \"square\",\n",
    "    \"meter\",\n",
    "    \"metre\",\n",
    "    \"feet\",\n",
    "    \"foot\",\n",
    "    ## common rooms\n",
    "    \"room\",\n",
    "    \"bedroom\",\n",
    "    \"bathroom\",\n",
    "    \"bath\",\n",
    "    \"washroom\",\n",
    "    \"dining\",\n",
    "    \"living\",\n",
    "    \"kitchen\",\n",
    "    \n",
    "    \"hallway\",\n",
    "    \"corridor\",\n",
    "    \n",
    "    ## common occurance\n",
    "    \"extra\"\n",
    "    \n",
    "    ## type of the building\n",
    "    #\"apartment\",\n",
    "    #\"condo\",\n",
    "    #\"condominium\",\n",
    "    #\"home\",\n",
    "    #\"house\",\n",
    "    #\"unit\",\n",
    "    ## describe the appliances, too common\n",
    "    #\"stainless\",\n",
    "    #\"steel\",\n",
    "    ## common appliances\n",
    "    #\"washer\",\n",
    "    #\"dryer\",\n",
    "    #\"stove\",\n",
    "    #\"fridge\"\n",
    "    ]\n",
    "\n",
    "all_stop_words=stopwords_nltk+real_estate_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].apply(lambda x: [word for word in x if word not in all_stop_words] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## detokenization and check unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"]=df[\"description\"].apply(lambda x: \" \".join(word for word in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Unique words\n",
    "uniqueWords = list(set(\" \".join(df['description']).split(\" \")))\n",
    "count = len(uniqueWords)\n",
    "print(\"Number of unique words is: \"+str(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check n-gram, and word cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check 1-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## This is the list of all the words in the description column\n",
    "totalWords = list(\" \".join(df['description']).split(\" \"))\n",
    "\n",
    "(pd.Series(nltk.ngrams(totalWords, 1)).value_counts())[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check 2-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.Series(nltk.ngrams(totalWords, 2)).value_counts())[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check 3-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.Series(nltk.ngrams(totalWords, 3)).value_counts())[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check 4-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(pd.Series(nltk.ngrams(totalWords, 4)).value_counts())[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word cloud for all description data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(des for des in df.description)\n",
    "print (\"There are {} words in the combination of all description.\".format(len(text)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Generate a word cloud image\n",
    "wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(text)#max_font_size=100, max_words=500,\n",
    "\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "plt.figure(figsize = (50, 50))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.Price.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word cloud for cheap 25% listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_25cheapest=df.sort_values(by=[\"Price\"])[:176]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(des for des in df_25cheapest.description)\n",
    "print (\"There are {} words in the combination of all description.\".format(len(text)))\n",
    "\n",
    "# Generate a word cloud image\n",
    "wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(text)#max_font_size=100, max_words=500,\n",
    "\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "plt.figure(figsize = (50, 50))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word cloud for middle price listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_middle=df.sort_values(by=[\"Price\"])[176:525]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(des for des in df_middle.description)\n",
    "print (\"There are {} words in the combination of all description.\".format(len(text)))\n",
    "\n",
    "# Generate a word cloud image\n",
    "wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(text)#max_font_size=100, max_words=500,\n",
    "\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "plt.figure(figsize = (100, 100))\n",
    "plt.imshow(wordcloud, interpolation='None')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word cloud for most expensive 25% listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_25highest=df.sort_values(by=[\"Price\"], ascending=False)[:176]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "text = \" \".join(des for des in df_25highest.description)\n",
    "print (\"There are {} words in the combination of all description.\".format(len(text)))\n",
    "\n",
    "# Generate a word cloud image\n",
    "wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(text)#max_font_size=100, max_words=500,\n",
    "\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "plt.figure(figsize = (100, 100))\n",
    "plt.imshow(wordcloud, interpolation='None')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenization again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokeniser = RegexpTokenizer(r'\\w+')\n",
    "df[\"description\"]=df[\"description\"].apply(lambda x: tokeniser.tokenize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "df[\"description\"]=df[\"description\"].apply(lambda x: [stemmer.stem(i) for i in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "df.description.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df[\"description\"]=df[\"description\"].apply(lambda x: \" \".join(word for word in x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## output processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.to_csv(output_folder+\"/all_after_preprocessingStopwords.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of TfidfVectorizer\n",
    "# ngram_range: (1,3) from 1-gram to 3-gram are included\n",
    "# min_df = the smallest number of rows that the word has occured in for the word to be included\n",
    "# min_df = the largest number of rows that the word has occured in for the word to be included\n",
    "\n",
    "#consider both unigram, bigram and trigram\n",
    "vectoriser = TfidfVectorizer(analyzer='word', min_df=0.03, max_df=0.95) # ngram_range=(1,3),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit to the data and transform to feature matrix\n",
    "# just check the first 5 rows\n",
    "vectors = vectoriser.fit_transform(df['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectoriser.get_feature_names_out()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df_desc = pd.DataFrame(denselist, columns=feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('float_format', '{:.5f}'.format)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_desc.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_desc.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None) #description full display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The word, and the number of non-zero rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_desc.astype(bool).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_price=df[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check the sum of the tf-idf score for cheapest 515 and most expensive 515 listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc2=df_desc.copy()\n",
    "df_desc22=pd.concat([df_desc2,labels_price], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5cheapest=df_desc22.sort_values(by=[\"price\"])[:516]\n",
    "sums_cheap = df_5cheapest.sum().rename('total')\n",
    "\n",
    "df_5expensive=df_desc22.sort_values(by=[\"price\"], ascending=False)[:516]\n",
    "sums_expensive=df_5expensive.sum().rename('total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sums_cheap.sort_values(ascending=False)[1:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums_expensive.sort_values(ascending=False)[1:20]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization of price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "labels_price = pd.DataFrame(scaler.fit_transform(pd.DataFrame(labels_price)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_price.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the MinMax Scaler model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import joblib\n",
    "joblib.dump(scaler, output_folder+\"/minmax_scaler.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or Log of the price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels_price = np.log2(labels_price)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels_price.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the distribution of price column (logged price, or normalized price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set(style='whitegrid', palette=\"deep\", font_scale=1.1, rc={\"figure.figsize\": [20, 8]})\n",
    "sns.distplot(\n",
    "    labels_price, norm_hist=False, kde=True, bins=40, hist_kws={\"alpha\": 1}).set(xlabel='price', ylabel='count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Use Gradient Boosting only on description data (TF-IDF converted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## implement MAPE(mean absolute percentage error) as customized scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "import numpy as np\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "\n",
    "\n",
    "MAPE=make_scorer(mean_absolute_percentage_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## divide dataset into training data and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_desc, labels_price, test_size=0.1, random_state=46) #random state=13 originally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "### Long Short Term Memory, when only description data is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dimension=len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert it to 3d because LSTM wants 3d input\n",
    "#X_train=X_train.to_numpy()\n",
    "#X_train = X_train[:, :, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to create model, required for KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "# Define the model creation function\n",
    "def create_model(learn_rate=0.001, amsgrad=False, activation='relu', dropout_rate=0.0, neurons=50):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons * 2, activation=activation))\n",
    "    model.add(Dropout(dropout_rate / 2))\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile model\n",
    "    optimizer = Adam(learning_rate=learn_rate, amsgrad=amsgrad)\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "# Custom wrapper class to use Keras model with Scikit-Learn\n",
    "class CustomKerasRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, build_fn, epochs=100, batch_size=10, **kwargs):\n",
    "        self.build_fn = build_fn  # Pass the build_fn here\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.kwargs = kwargs\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y, **fit_params):\n",
    "        self.model = self.build_fn(**self.kwargs)\n",
    "        self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, **fit_params)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X).flatten()\n",
    "\n",
    "    def score(self, X, y):\n",
    "        from sklearn.metrics import mean_squared_error\n",
    "        return -mean_squared_error(y, self.predict(X))\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {\"build_fn\": self.build_fn, \"epochs\": self.epochs, \"batch_size\": self.batch_size, **self.kwargs}\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        self.epochs = params.pop(\"epochs\", self.epochs)\n",
    "        self.batch_size = params.pop(\"batch_size\", self.batch_size)\n",
    "        self.kwargs.update(params)\n",
    "        return self\n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Instantiate the model using the custom class with the build function passed in\n",
    "model = CustomKerasRegressor(build_fn=create_model, epochs=100, batch_size=10, learn_rate=0.001, amsgrad=False, activation='relu', dropout_rate=0.0, neurons=50)\n",
    "\n",
    "# Define the grid search parameters\n",
    "batch_size = [10, 20]\n",
    "epochs = [50, 75, 100]\n",
    "learn_rate = [0.0001, 0.001, 0.01]\n",
    "amsgrad = [False]\n",
    "activation = ['relu', 'sigmoid']\n",
    "dropout_rate = [0.1, 0.2]\n",
    "neurons = [50, 100]\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs, learn_rate=learn_rate, amsgrad=amsgrad,\n",
    "                  activation=activation, dropout_rate=dropout_rate, neurons=neurons)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5, verbose=10, \n",
    "                    scoring=('r2', 'neg_root_mean_squared_error'), refit='r2')\n",
    "\n",
    "# Fit the grid search model\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Summarize the results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"Neural Network Grid Search Results\")\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid.best_estimator_)\n",
    "print(\"\\n The best r2 score across ALL searched params:\\n\",grid.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid.best_params_)\n",
    "print(\"\\n\")\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"All Results:\") \n",
    "\n",
    "param_com=grid.cv_results_['params']\n",
    "r2_scores=grid.cv_results_['mean_test_r2']\n",
    "rmse_scores=grid.cv_results_['mean_test_neg_root_mean_squared_error']\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "index=0\n",
    "for item in param_com:\n",
    "    print(\"parameter combinations:\"+str(item))\n",
    "    print(\"\\n\")\n",
    "    print(\"test r2 score:\"+str(r2_scores[index]))\n",
    "    print(\"\\n\")\n",
    "    print(\"test RMSE score:\"+str(rmse_scores[index]*-1))\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    index=index+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gd_result = pd.DataFrame(grid.cv_results_)\n",
    "gd_result=gd_result[['param_batch_size','param_epochs', 'param_neurons','param_activation','param_learn_rate', 'param_dropout_rate', 'mean_test_r2','mean_test_neg_root_mean_squared_error'  ]]\n",
    "gd_result=gd_result.sort_values(by=['mean_test_r2', 'mean_test_neg_root_mean_squared_error'], ascending=False)\n",
    "gd_result.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_result.to_csv(output_folder+\"/\"+\"gridsearch_NN_TF_IDF_descriptiononly_5fold_bound.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "### Random Forest, when only description data is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import ensemble\n",
    "GBR = ensemble.RandomForestRegressor()\n",
    "\n",
    "\n",
    "parameters = {'bootstrap': [True, False],\n",
    "              'max_depth': [5, 10, 20, 30, None],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'n_estimators': [32, 64, 100, 500, 1000]}\n",
    "\n",
    "y_train_flat=np.ravel(y_train)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_GBR = GridSearchCV(estimator=GBR, param_grid = parameters,scoring=('r2', 'neg_root_mean_squared_error'),refit='r2', verbose=10, cv = 5, n_jobs=-1)\n",
    "grid_GBR.fit(X_train, y_train_flat)\n",
    "\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"Gradient Boosting Grid Search Results\")\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid_GBR.best_estimator_)\n",
    "print(\"\\n The best r2 score across ALL searched params:\\n\",grid_GBR.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_GBR.best_params_)\n",
    "print(\"\\n\")\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"All Results:\") \n",
    "\n",
    "param_com=grid_GBR.cv_results_['params']\n",
    "r2_scores=grid_GBR.cv_results_['mean_test_r2']\n",
    "rmse_scores=grid_GBR.cv_results_['mean_test_neg_root_mean_squared_error']\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "index=0\n",
    "for item in param_com:\n",
    "    print(\"parameter combinations:\"+str(item))\n",
    "    print(\"\\n\")\n",
    "    print(\"test r2 score:\"+str(r2_scores[index]))\n",
    "    print(\"\\n\")\n",
    "    print(\"test RMSE score:\"+str(rmse_scores[index]*-1))\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    index=index+1\n",
    "\n",
    "\n",
    "df_gridsearch_result = pd.DataFrame(grid_GBR.cv_results_)\n",
    "\n",
    "\n",
    "gd_result=df_gridsearch_result[['param_n_estimators','param_max_depth','param_max_features','param_bootstrap','mean_test_r2','mean_test_neg_root_mean_squared_error'  ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gd_result=gd_result.sort_values(by=['mean_test_r2', 'mean_test_neg_root_mean_squared_error'], ascending=False)\n",
    "gd_result.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_result.to_csv(output_folder+\"/\"+\"gridsearch_randomforest_TF_IDF_descriptiononly_5fold.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "### Gradient Boosting, when only description data is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import ensemble\n",
    "GBR = ensemble.GradientBoostingRegressor()\n",
    "\n",
    "parameters = {'n_estimators' : [500,1000], # 100 removed\n",
    "              'max_depth'    : [4,6], # 3 removed\n",
    "              'learning_rate': [0.01,0.02], # 0.005 removed\n",
    "              'subsample'    : [1, 0.8] \n",
    "             }\n",
    "\n",
    "y_train_flat=np.ravel(y_train)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_GBR = GridSearchCV(estimator=GBR, param_grid = parameters,scoring=('r2', 'neg_root_mean_squared_error'),refit='r2', verbose=10, cv = 5, n_jobs=-1)\n",
    "grid_GBR.fit(X_train, y_train_flat)\n",
    "\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"Gradient Boosting Grid Search Results\")\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid_GBR.best_estimator_)\n",
    "print(\"\\n The best r2 score across ALL searched params:\\n\",grid_GBR.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_GBR.best_params_)\n",
    "print(\"\\n\")\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"All Results:\") \n",
    "\n",
    "param_com=grid_GBR.cv_results_['params']\n",
    "r2_scores=grid_GBR.cv_results_['mean_test_r2']\n",
    "rmse_scores=grid_GBR.cv_results_['mean_test_neg_root_mean_squared_error']\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "index=0\n",
    "for item in param_com:\n",
    "    print(\"parameter combinations:\"+str(item))\n",
    "    print(\"\\n\")\n",
    "    print(\"test r2 score:\"+str(r2_scores[index]))\n",
    "    print(\"\\n\")\n",
    "    print(\"test RMSE score:\"+str(rmse_scores[index]*-1))\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    index=index+1\n",
    "\n",
    "\n",
    "df_gridsearch_result = pd.DataFrame(grid_GBR.cv_results_)\n",
    "\n",
    "\n",
    "gd_result=df_gridsearch_result[['param_n_estimators','param_max_depth','param_learning_rate','param_subsample','mean_test_r2','mean_test_neg_root_mean_squared_error'  ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gd_result=gd_result.sort_values(by=['mean_test_r2', 'mean_test_neg_root_mean_squared_error'], ascending=False)\n",
    "gd_result.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_result.to_csv(output_folder+\"/\"+\"gridsearch_gradientboosting_TF_IDF_descriptiononly_5fold.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## These blocks may take some minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "params = {'n_estimators': 1000,\n",
    "          'max_depth': 4,\n",
    "          'min_samples_split': 5,\n",
    "          'learning_rate': 0.01,\n",
    "          'loss': 'ls'}\n",
    "\n",
    "reg = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "y_train_flat=np.ravel(y_train)\n",
    "reg.fit(X_train, y_train_flat)\n",
    "\n",
    "#mse = mean_squared_error(y_test, reg.predict(X_test), squared=False)\n",
    "\n",
    "#print(\"The root mean squared error (RMSE) on test set: {:.4f}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check how long it takes to finish the cross-validation\n",
    "import time\n",
    "tic = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "scores = cross_validate(reg, X_train, y_train_flat, scoring=('r2', 'neg_root_mean_squared_error'), cv=10, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "sorted(metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, r2_score, mean_squared_error\n",
    "\n",
    "# Custom scoring functions\n",
    "scoring = {\n",
    "    'r2': make_scorer(r2_score),\n",
    "    'neg_root_mean_squared_error': make_scorer(lambda y_true, y_pred: -mean_squared_error(y_true, y_pred, squared=False))\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    refit='r2',\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best estimator:\", grid.best_estimator_)\n",
    "print(\"Best score:\", grid.best_score_)\n",
    "print(\"Best params:\", grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"RMSE training Score using cv: {:0.5f}\".format(scores['train_neg_root_mean_squared_error'].mean() * -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE test Score using cv: {:0.5f}\".format(scores['test_neg_root_mean_squared_error'].mean() * -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 training Score using cv: {:0.5f}\".format(scores['train_r2'].mean() * -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 test Score using cv: {:0.5f}\".format(scores['test_r2'].mean() * -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = time.perf_counter()\n",
    "print(f\"Finish cross validation in  {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tic = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores=cross_val_score(reg, X_train, y_train_flat, scoring=\"r2\", cv=10)\n",
    "print(\"RMSE test Score using cv_score: {:0.5f}\".format(scores.mean() * -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "toc = time.perf_counter()\n",
    "print(f\"Finish cross validation in  {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try to use all the features to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features=[\"Bedrooms\",\"Baths\", \"Size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "X_num=df[numerical_features]\n",
    "X_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization for numerical data using MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# recaling the variables (both)\n",
    "X_num_columns = X_num.columns\n",
    "scaler = MinMaxScaler()\n",
    "X_num = scaler.fit_transform(X_num)\n",
    "\n",
    "# rename columns (since now its an np array)\n",
    "X_num = pd.DataFrame(X_num)\n",
    "X_num.columns = X_num_columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization for longitude and latitude sepeparately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert categorical data with string values into numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat=df[['Location']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## convert categorical data to numerical values\n",
    "cat_features=['Location']\n",
    "for col in cat_features:\n",
    "    X_cat[col] = X_cat[col].astype('category')\n",
    "    X_cat[col] = X_cat[col].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the categorical data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# recaling the variables (both)\n",
    "X_cat_columns = X_cat.columns\n",
    "scaler = MinMaxScaler()\n",
    "X_cat = scaler.fit_transform(X_cat)\n",
    "\n",
    "# rename columns (since now its an np array)\n",
    "X_cat = pd.DataFrame(X_cat)\n",
    "X_cat.columns = X_cat_columns\n",
    "\n",
    "X_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use numerical, categorical, and description data to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_all = pd.concat([X_num, X_cat, df_desc], axis=1)\n",
    "X_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## divide dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, labels_price, test_size=0.1, random_state=13) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train).astype(np.float32)\n",
    "X_test = np.asarray(X_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "### Long Short Term Memory, when all features are used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to create model, required for KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "def create_model(learn_rate=0.001, amsgrad=False, activation='relu', dropout_rate=0.0, neurons=50):\n",
    "    # create model\n",
    "    # The maximum number of words to be used. (most frequent)\n",
    "    #MAX_NB_WORDS = 50000\n",
    "    # embedding dimension\n",
    "    #EMBEDDING_DIM = 100\n",
    "    #model.add(Dense(1024, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    #model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "    #model.add(LSTM(50))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation=activation)) #input_shape=(X_train.shape[1],), return_sequences = True\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons*2, activation=activation))\n",
    "    model.add(Dropout(dropout_rate/2))\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid')) #\n",
    "\n",
    "    # Compile model\n",
    "    optimizer = Adam(learning_rate=learn_rate, amsgrad=amsgrad)\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "# create model\n",
    "model = KerasRegressor(build_fn=create_model, verbose=10) #epochs=75, batch_size=10, verbose=10)\n",
    "# define the grid search parameters\n",
    "#optimizer = ['Adam'] \n",
    "batch_size = [10, 20] # 5, 10,\n",
    "epochs = [50, 75, 100] # ,50, 75,\n",
    "learn_rate = [0.0001,0.001,0.01] #0.0001, , 0.01, 0.0001,0.001,\n",
    "amsgrad = [False] # True,  #True,\n",
    "activation = ['relu', 'sigmoid']#, 'softplus'] #, 'sigmoid','softplus'] #, , 'softsign', 'hard_sigmoid', 'softmax', #, 'linear' \n",
    "dropout_rate = [0.1,0.2] #,0.2,0.3]#, 0.2] #0.0,, 0.3, 0.5 0.4, 0.2,, 0.3, 0.4, 0.5, 0.7\n",
    "neurons = [50, 100] #25, 50, 100, 150,300, 200\n",
    "\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs, learn_rate=learn_rate, amsgrad=amsgrad, activation=activation, dropout_rate=dropout_rate, neurons=neurons)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5, verbose=10, scoring=('r2', 'neg_root_mean_squared_error'), refit='r2')\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"Neural Network Grid Search Results\")\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid.best_estimator_)\n",
    "print(\"\\n The best r2 score across ALL searched params:\\n\",grid.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid.best_params_)\n",
    "print(\"\\n\")\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"All Results:\") \n",
    "\n",
    "param_com=grid.cv_results_['params']\n",
    "r2_scores=grid.cv_results_['mean_test_r2']\n",
    "rmse_scores=grid.cv_results_['mean_test_neg_root_mean_squared_error']\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "index=0\n",
    "for item in param_com:\n",
    "    print(\"parameter combinations:\"+str(item))\n",
    "    print(\"\\n\")\n",
    "    print(\"test r2 score:\"+str(r2_scores[index]))\n",
    "    print(\"\\n\")\n",
    "    print(\"test RMSE score:\"+str(rmse_scores[index]*-1))\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    index=index+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gd_result = pd.DataFrame(grid.cv_results_)\n",
    "gd_result=gd_result[['param_batch_size','param_epochs', 'param_neurons','param_activation','param_learn_rate', 'param_dropout_rate', 'mean_test_r2','mean_test_neg_root_mean_squared_error'  ]]\n",
    "gd_result=gd_result.sort_values(by=['mean_test_r2', 'mean_test_neg_root_mean_squared_error'], ascending=False)\n",
    "gd_result.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_result.to_csv(output_folder+\"/\"+\"gridsearch_NN_TF_IDF_all_5fold_bound.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "### Random Forest, when all features are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import ensemble\n",
    "GBR = ensemble.RandomForestRegressor()\n",
    "\n",
    "\n",
    "parameters = {'bootstrap': [True, False],\n",
    "              'max_depth': [5, 10, 20, 30, None],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'n_estimators': [32, 64, 100, 500, 1000]}\n",
    "\n",
    "y_train_flat=np.ravel(y_train)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_GBR = GridSearchCV(estimator=GBR, param_grid = parameters,scoring=('r2', 'neg_root_mean_squared_error'),refit='r2', verbose=10, cv = 5, n_jobs=-1)\n",
    "grid_GBR.fit(X_train, y_train_flat)\n",
    "\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"Gradient Boosting Grid Search Results\")\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid_GBR.best_estimator_)\n",
    "print(\"\\n The best r2 score across ALL searched params:\\n\",grid_GBR.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_GBR.best_params_)\n",
    "print(\"\\n\")\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"All Results:\") \n",
    "\n",
    "param_com=grid_GBR.cv_results_['params']\n",
    "r2_scores=grid_GBR.cv_results_['mean_test_r2']\n",
    "rmse_scores=grid_GBR.cv_results_['mean_test_neg_root_mean_squared_error']\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "index=0\n",
    "for item in param_com:\n",
    "    print(\"parameter combinations:\"+str(item))\n",
    "    print(\"\\n\")\n",
    "    print(\"test r2 score:\"+str(r2_scores[index]))\n",
    "    print(\"\\n\")\n",
    "    print(\"test RMSE score:\"+str(rmse_scores[index]*-1))\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    index=index+1\n",
    "\n",
    "\n",
    "df_gridsearch_result = pd.DataFrame(grid_GBR.cv_results_)\n",
    "\n",
    "\n",
    "gd_result=df_gridsearch_result[['param_n_estimators','param_max_depth','param_max_features','param_bootstrap','mean_test_r2','mean_test_neg_root_mean_squared_error'  ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gd_result=gd_result.sort_values(by=['mean_test_r2', 'mean_test_neg_root_mean_squared_error'], ascending=False)\n",
    "gd_result.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_result.to_csv(output_folder+\"/\"+\"gridsearch_randomforest_TF_IDF_all_5fold.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "### Gradient Boosting, when all the features are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "GBR = ensemble.GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_estimators' : [500,1000], # 100 removed\n",
    "              'max_depth'    : [4,6], # 3 removed\n",
    "              'learning_rate': [0.01,0.02], # 0.005 removed\n",
    "              'subsample'    : [1, 0.8] \n",
    "             }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_flat=np.ravel(y_train)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_GBR = GridSearchCV(estimator=GBR, param_grid = parameters,scoring=('r2', 'neg_root_mean_squared_error'),refit='r2', verbose=10, cv = 5, n_jobs=-1)\n",
    "grid_GBR.fit(X_train, y_train_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"Gradient Boosting Grid Search Results\")\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid_GBR.best_estimator_)\n",
    "print(\"\\n The best r2 score across ALL searched params:\\n\",grid_GBR.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_GBR.best_params_)\n",
    "print(\"\\n\")\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"All Results:\") \n",
    "\n",
    "param_com=grid_GBR.cv_results_['params']\n",
    "r2_scores=grid_GBR.cv_results_['mean_test_r2']\n",
    "rmse_scores=grid_GBR.cv_results_['mean_test_neg_root_mean_squared_error']\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "index=0\n",
    "for item in param_com:\n",
    "    print(\"parameter combinations:\"+str(item))\n",
    "    print(\"\\n\")\n",
    "    print(\"test r2 score:\"+str(r2_scores[index]))\n",
    "    print(\"\\n\")\n",
    "    print(\"test RMSE score:\"+str(rmse_scores[index]*-1))\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    index=index+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gridsearch_result = pd.DataFrame(grid_GBR.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_result=df_gridsearch_result[['param_n_estimators','param_max_depth','param_learning_rate','param_subsample','mean_test_r2','mean_test_neg_root_mean_squared_error'  ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gd_result=gd_result.sort_values(by=['mean_test_r2', 'mean_test_neg_root_mean_squared_error'], ascending=False)\n",
    "gd_result.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_result.to_csv(output_folder+\"/\"+\"gridsearch_gradientboosting_TF_IDF_all_5fold.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create gradient boosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "params = {'n_estimators': 1000,\n",
    "          'max_depth': 4,\n",
    "          'min_samples_split': 5,\n",
    "          'learning_rate': 0.01,\n",
    "          'loss': 'ls'}\n",
    "\n",
    "reg = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "y_train_flat=np.ravel(y_train)\n",
    "reg.fit(X_train, y_train_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## do cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "tic = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "scores = cross_validate(reg, X_train, y_train_flat, scoring=('r2', 'neg_root_mean_squared_error'), cv=10, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE training Score using cv: {:0.5f}\".format(scores['train_neg_root_mean_squared_error'].mean() * -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"RMSE test Score using cv: {:0.5f}\".format(scores['test_neg_root_mean_squared_error'].mean() * -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 training Score using cv: {:0.5f}\".format(scores['train_r2'].mean() * -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 test Score using cv: {:0.5f}\".format(scores['test_r2'].mean() * -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "toc = time.perf_counter()\n",
    "print(f\"Finish cross validation in  {(toc - tic)/60:0.4f} minutes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use numerical, boolean, categorical (excluding description) data to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_all_exdesc = pd.concat([X_num, X_boo, X_category], axis=1)\n",
    "X_all_exdesc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## divide dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all_exdesc, labels_price, test_size=0.1, random_state=13) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train).astype(np.float32)\n",
    "X_test = np.asarray(X_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "### Long Short Term Memory, when no description data is used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to create model, required for KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "def create_model(learn_rate=0.001, amsgrad=False, activation='relu', dropout_rate=0.0, neurons=50):\n",
    "    # create model\n",
    "    # The maximum number of words to be used. (most frequent)\n",
    "    #MAX_NB_WORDS = 50000\n",
    "    # embedding dimension\n",
    "    #EMBEDDING_DIM = 100\n",
    "    #model.add(Dense(1024, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    #model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "    #model.add(LSTM(50))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation=activation)) #input_shape=(X_train.shape[1],), return_sequences = True\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons*2, activation=activation))\n",
    "    model.add(Dropout(dropout_rate/2))\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid')) #\n",
    "\n",
    "    # Compile model\n",
    "    optimizer = Adam(learning_rate=learn_rate, amsgrad=amsgrad)\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "# create model\n",
    "model = KerasRegressor(build_fn=create_model, verbose=10) #epochs=75, batch_size=10, verbose=10)\n",
    "# define the grid search parameters\n",
    "#optimizer = ['Adam'] \n",
    "batch_size = [10,20] # 5, \n",
    "epochs = [50, 75, 100] # ,\n",
    "learn_rate = [0.0001,0.001,0.01] #0.0001, , 0.01\n",
    "amsgrad = [False] # True,  #True,\n",
    "activation = ['relu', 'sigmoid']#, 'softplus'] #, 'sigmoid','softplus'] #, , 'softsign', 'hard_sigmoid', 'softmax', #, 'linear' \n",
    "dropout_rate = [0.1,0.2] #,0.3]#, 0.2] #0.0,, 0.3, 0.5 0.4, 0.2,, 0.3, 0.4, 0.5, 0.7\n",
    "neurons = [50, 100] #25, 50, 100, 150,300, 200\n",
    "\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs, learn_rate=learn_rate, amsgrad=amsgrad, activation=activation, dropout_rate=dropout_rate, neurons=neurons)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5, verbose=10, scoring=('r2', 'neg_root_mean_squared_error'), refit='r2')\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"Neural Network Grid Search Results\")\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid.best_estimator_)\n",
    "print(\"\\n The best r2 score across ALL searched params:\\n\",grid.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid.best_params_)\n",
    "print(\"\\n\")\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"All Results:\") \n",
    "\n",
    "param_com=grid.cv_results_['params']\n",
    "r2_scores=grid.cv_results_['mean_test_r2']\n",
    "rmse_scores=grid.cv_results_['mean_test_neg_root_mean_squared_error']\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "index=0\n",
    "for item in param_com:\n",
    "    print(\"parameter combinations:\"+str(item))\n",
    "    print(\"\\n\")\n",
    "    print(\"test r2 score:\"+str(r2_scores[index]))\n",
    "    print(\"\\n\")\n",
    "    print(\"test RMSE score:\"+str(rmse_scores[index]*-1))\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    index=index+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gd_result = pd.DataFrame(grid.cv_results_)\n",
    "gd_result=gd_result[['param_batch_size','param_epochs', 'param_neurons','param_activation','param_learn_rate', 'param_dropout_rate', 'mean_test_r2','mean_test_neg_root_mean_squared_error'  ]]\n",
    "gd_result=gd_result.sort_values(by=['mean_test_r2', 'mean_test_neg_root_mean_squared_error'], ascending=False)\n",
    "gd_result.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_result.to_csv(output_folder+\"/\"+\"gridsearch_NN_TF_IDF_nodescription_5fold_bound.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "### Random Forest, when no description data is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import ensemble\n",
    "GBR = ensemble.RandomForestRegressor()\n",
    "\n",
    "\n",
    "parameters = {'bootstrap': [True, False],\n",
    "              'max_depth': [5, 10, 20, 30, None],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'n_estimators': [32, 64, 100, 500, 1000]}\n",
    "\n",
    "y_train_flat=np.ravel(y_train)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_GBR = GridSearchCV(estimator=GBR, param_grid = parameters,scoring=('r2', 'neg_root_mean_squared_error'),refit='r2', verbose=10, cv = 5, n_jobs=-1)\n",
    "grid_GBR.fit(X_train, y_train_flat)\n",
    "\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"Gradient Boosting Grid Search Results\")\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid_GBR.best_estimator_)\n",
    "print(\"\\n The best r2 score across ALL searched params:\\n\",grid_GBR.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_GBR.best_params_)\n",
    "print(\"\\n\")\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"All Results:\") \n",
    "\n",
    "param_com=grid_GBR.cv_results_['params']\n",
    "r2_scores=grid_GBR.cv_results_['mean_test_r2']\n",
    "rmse_scores=grid_GBR.cv_results_['mean_test_neg_root_mean_squared_error']\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "index=0\n",
    "for item in param_com:\n",
    "    print(\"parameter combinations:\"+str(item))\n",
    "    print(\"\\n\")\n",
    "    print(\"test r2 score:\"+str(r2_scores[index]))\n",
    "    print(\"\\n\")\n",
    "    print(\"test RMSE score:\"+str(rmse_scores[index]*-1))\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    index=index+1\n",
    "\n",
    "\n",
    "df_gridsearch_result = pd.DataFrame(grid_GBR.cv_results_)\n",
    "\n",
    "\n",
    "gd_result=df_gridsearch_result[['param_n_estimators','param_max_depth','param_max_features','param_bootstrap','mean_test_r2','mean_test_neg_root_mean_squared_error'  ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gd_result=gd_result.sort_values(by=['mean_test_r2', 'mean_test_neg_root_mean_squared_error'], ascending=False)\n",
    "gd_result.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_result.to_csv(output_folder+\"/\"+\"gridsearch_randomforest_TF_IDF_nodescription_5fold.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "### Gradient Boosting, when only non-description data is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import ensemble\n",
    "GBR = ensemble.GradientBoostingRegressor()\n",
    "\n",
    "parameters = {'n_estimators' : [500,1000], # 100 removed\n",
    "              'max_depth'    : [4,6], # 3 removed\n",
    "              'learning_rate': [0.01,0.02], # 0.005 removed\n",
    "              'subsample'    : [1, 0.8] \n",
    "             }\n",
    "\n",
    "\n",
    "y_train_flat=np.ravel(y_train)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_GBR = GridSearchCV(estimator=GBR, param_grid = parameters,scoring=('r2', 'neg_root_mean_squared_error'),refit='r2', verbose=10, cv = 5, n_jobs=-1)\n",
    "grid_GBR.fit(X_train, y_train_flat)\n",
    "\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"Gradient Boosting Grid Search Results\")\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid_GBR.best_estimator_)\n",
    "print(\"\\n The best r2 score across ALL searched params:\\n\",grid_GBR.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_GBR.best_params_)\n",
    "print(\"\\n\")\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"All Results:\") \n",
    "\n",
    "param_com=grid_GBR.cv_results_['params']\n",
    "r2_scores=grid_GBR.cv_results_['mean_test_r2']\n",
    "rmse_scores=grid_GBR.cv_results_['mean_test_neg_root_mean_squared_error']\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "index=0\n",
    "for item in param_com:\n",
    "    print(\"parameter combinations:\"+str(item))\n",
    "    print(\"\\n\")\n",
    "    print(\"test r2 score:\"+str(r2_scores[index]))\n",
    "    print(\"\\n\")\n",
    "    print(\"test RMSE score:\"+str(rmse_scores[index]*-1))\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    index=index+1\n",
    "\n",
    "\n",
    "df_gridsearch_result = pd.DataFrame(grid_GBR.cv_results_)\n",
    "\n",
    "\n",
    "gd_result=df_gridsearch_result[['param_n_estimators','param_max_depth','param_learning_rate','param_subsample','mean_test_r2','mean_test_neg_root_mean_squared_error'  ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gd_result=gd_result.sort_values(by=['mean_test_r2', 'mean_test_neg_root_mean_squared_error'], ascending=False)\n",
    "gd_result.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_result.to_csv(output_folder+\"/\"+\"gridsearch_gradientboosting_nodescription_5fold.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create gradient boosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "params = {'n_estimators': 1000,\n",
    "          'max_depth': 4,\n",
    "          'min_samples_split': 5,\n",
    "          'learning_rate': 0.01,\n",
    "          'loss': 'ls'}\n",
    "\n",
    "reg = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "y_train_flat=np.ravel(y_train)\n",
    "reg.fit(X_train, y_train_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## do cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "tic = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "scores = cross_validate(reg, X_train, y_train_flat, scoring=\"r2\", cv=10, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"RMSE training Score using cv: {:0.5f}\".format(scores['train_score'].mean() * -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"RMSE test Score using cv: {:0.5f}\".format(scores['test_score'].mean() * -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = time.perf_counter()\n",
    "print(f\"Finish cross validation in  {(toc - tic)/60:0.4f} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
